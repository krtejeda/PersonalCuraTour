---
title: Usability Testing Checkin
layout: page
---

# Cognitive Walkthroughs

![](https://krtejeda.github.io/PersonalCuraTour/img/cogWalkthrough1.jpg)

![](https://krtejeda.github.io/PersonalCuraTour/img/cogWalkthrough2.jpg)

## Issues uncovered during walkthrough

| Photo of Prototype | Description of Incident | Photo of Revision |
| -------- | -------- | -------- |
| A | In our screen for selection of a guided tour, it is not evident that the buttons select for exhibits.  It is not clear from the buttons that what kind of tour is being selected, one that focuses on an exhibit or the entire museum, for example, or even the creator of the tour.  |  X |
| -------- | -------- | -------- |
| B | Need a “no audio” option for those who just want guidance to pieces, without voice-overs playing. | X |
| -------- | -------- | -------- |
| C | There is no option for the user to not rate the tour, but we are not giving users the option to not rate tours in order to force the generation of sufficient feedback | No revision made |
| -------- | -------- | -------- |
| D | The end experience button should be an ‘x’ instead of an arrow, to more graphically correspond with the action being executed | X |
| -------- | -------- | -------- |
| E | The user might want the option to enter the title of the tour differently--for example, to enter the title via voice input.  We will not make this change because it would disrupt the quiet environment of a museum  | No revision made |
| -------- | -------- | -------- |

![](https://krtejeda.github.io/PersonalCuraTour/img/cogWalkthroughImg.jpg)


# Plan for additional tests

Our plan for the remainder of the usability testing is to target several different user demographics as they relate to level of prior experience.  The test we have already done focused on an individual who had a moderate level of experience with museums.  She was a studio art major, implying that she had a higher sense of aesthetics, as stated, but was not highly experienced with museums.  This means that she had valuable insights from the perspective of an individual who has moderate experience with museums, but is not a total expert.  To cover the two other user bases that we are interested in, we will also try to conduct a test on someone who is an expert at museums, or is at least someone who has gone often to many different museums.  This will allow us to hear the views of someone who has lots of prior experience with exhibits, knows the mode of interaction desired, and even potentially has used other types of MuseTech and will be able to make useful contrasts.  Lastly, we will also seek out an inexperienced user to test upon.  This will provide insight with how a user with less preconceptions may view the prototype, and how it may help them relate to art.

The other thing we may look into is changing the test environment itself.  The test we conducted occured in a more casual environment, a Schow study room, without much prior preparation.  This in itself could be improved upon, as we could work to set up a more realistic exhibit-like environment with at least one to two mock pieces that the user could physically transition between, since our application does not exist within a vacuum, but rather a very specific kind of environment.  Further, our application is heavily audio-based; a large portion of the watch interface is used to control the user’s interaction with the audio being played.  This means that the audio we simulate must be at least somewhat realistic in order to engender a believable response from the end user.  Therefore, we will either prepare a sample recording or at least write a script that one of our testers will read off of to simulate operation of this component of our app.  This will ostensibly improve the simulation over the ad-libbing that was done for our first round, which was better than nothing but certainly not quite there.

